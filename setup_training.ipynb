{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import json\n",
    "import pickle\n",
    "import pptk\n",
    "from pyntcloud import PyntCloud\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Now let's use this pointnet class\n",
    "class A2D2DataLoader(Dataset):\n",
    "    def __init__(self, dataset, rotation=None, \\\n",
    "                 normalize_xyz=True, normalize_rgb=True, \\\n",
    "                 take_subset=False, convert_to_tensor=True, \\\n",
    "                 target_ids=[3]):\n",
    "                 #target_ids=[19, 54, 26, 46, 7, 18, 31, 24, 16, 53, 33,\\\n",
    "                             #37, 15, 13, 41, 3, 10, 22, 6, 42, 23, 14, \\\n",
    "                            # 5, 9, 12, 21, 48]):\n",
    "        \n",
    "        # Get IDS\n",
    "        self.ids = list(dataset.keys())\n",
    "        \n",
    "        # Get rotation and length of dataset\n",
    "        self.rotation = rotation\n",
    "        self.N = len(self.ids)\n",
    "        \n",
    "        # Get geometric point cloud data and normalize\n",
    "        self.xyz = [dataset[ID]['points'] for ID in self.ids]\n",
    "        self.xyz_norm = self.normalize_xyz()\n",
    "        \n",
    "        # Get rgb data and normalize \n",
    "        self.rgb = [dataset[ID]['rgb'] for ID in self.ids]\n",
    "        self.rgb_norm = self.normalize_rgb()\n",
    "        \n",
    "        # Combine xyz and rgb\n",
    "        self.xyz_rgb = np.hstack((self.xyz, self.rgb))\n",
    "        self.xyz_rgb_norm = [np.hstack((self.xyz_norm[i], self.rgb_norm[i])) for i in range(self.N)]\n",
    "        \n",
    "        # Get labels\n",
    "        self.labels = [dataset[ID]['labels'] for ID in self.ids]\n",
    "        \n",
    "        # Get number of points to use\n",
    "        self.num_points  = np.min([len(self.xyz[i]) for i in range(self.N)])\n",
    "        print(\"SMALLEST PC POINTS: {}\".format(self.num_points))\n",
    "    \n",
    "        if take_subset:\n",
    "            self.target_ids = target_ids\n",
    "            # Now get subset\n",
    "            self.general_dataset, self.target_dataset = self.split_ds_by_classes()\n",
    "        if convert_to_tensor:\n",
    "            self.xyz_norm_tensor, self.rgb_norm_tensor, \\\n",
    "            self.xyz_rgb_norm_tensor, self.labels_tensor = self.convert_to_tensor()\n",
    "       \n",
    "                \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "\n",
    "    def rotate_point_cloud_by_angle(self, data, rotation_angle):\n",
    "        \"\"\"\n",
    "        Rotate the point cloud along up direction with certain angle.\n",
    "        :param batch_data: Nx3 array, original batch of point clouds\n",
    "        :param rotation_angle: range of rotation\n",
    "        :return:  Nx3 array, rotated batch of point clouds\n",
    "        \"\"\"\n",
    "        cosval = np.cos(rotation_angle)\n",
    "        sinval = np.sin(rotation_angle)\n",
    "        rotation_matrix = np.array([[cosval, 0, sinval],\n",
    "                                    [0, 1, 0],\n",
    "                                    [-sinval, 0, cosval]])\n",
    "        rotated_data = np.dot(data, rotation_matrix)\n",
    "\n",
    "        return rotated_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.rotation is not None:\n",
    "            index_xyz = self.xyz[index]\n",
    "            angle = np.random.randint(self.rotation[0], self.rotation[1]) * np.pi / 180\n",
    "            pointcloud = self.rotate_point_cloud_by_angle(index_xyz, angle)\n",
    "\n",
    "            return pointcloud, self.labels[index]\n",
    "        else:\n",
    "            return self.xyz_rgb_norm_tensor[index], self.labels_tensor[index], len(self.xyz_rgb_norm_tensor[index])\n",
    "    \n",
    "    def normalize_xyz(self):\n",
    "        normalized_xyz = []\n",
    "        for ID in range(len(self.ids)):\n",
    "            XYZ = np.copy(self.xyz[ID])\n",
    "            centroid = np.mean(XYZ, axis=0)\n",
    "            XYZ -= centroid\n",
    "            furthest_distance = np.max(np.sqrt(np.sum(abs(XYZ)**2,axis=-1)))\n",
    "            XYZ /= furthest_distance\n",
    "            normalized_xyz.append(XYZ) \n",
    "        print(\"XYZ normalized\")\n",
    "        return normalized_xyz\n",
    "    \n",
    "    def normalize_rgb(self):\n",
    "        normalized_rgb = []\n",
    "        for ID in range(len(self.ids)):\n",
    "            RGB = np.copy(self.rgb[ID])\n",
    "            RGB = np.divide(RGB, 255.0)\n",
    "            normalized_rgb.append(RGB)\n",
    "        print(\"RGB normalized\")\n",
    "        return normalized_rgb\n",
    "    \n",
    "    def convert_to_tensor(self):\n",
    "        \"\"\"\n",
    "        xyz_norm_tensor = torch.tensor(self.xyz_norm)\n",
    "        rgb_norm_tensor = torch.tensor(self.rgb_norm)\n",
    "        xyz_rgb_norm_tensor = torch.tensor(self.xyz_rgb_norm)\n",
    "        labels_tensor = torch.tensor(self.labels)\n",
    "        \"\"\"\n",
    "        xyz_norm_tensor = [torch.tensor(dp) for dp in self.xyz_norm]\n",
    "        rgb_norm_tensor = [torch.tensor(dp) for dp in self.rgb_norm]\n",
    "        xyz_rgb_norm_tensor = [torch.tensor(dp) for dp in self.xyz_rgb_norm]\n",
    "        labels_tensor = [torch.tensor(dp) for dp in self.labels]\n",
    "        \n",
    "        return xyz_norm_tensor, rgb_norm_tensor, xyz_rgb_norm_tensor, labels_tensor\n",
    "    \n",
    "    def split_ds_by_classes(self):\n",
    "        # Init output data structures\n",
    "        gen_ds, target_ds = {}, {}\n",
    "        \n",
    "        general_id_indices = [j for j in range(55) if j not in self.target_ids]\n",
    "        general_id_map = {general_id_indices[k]:k for k in range(len(general_id_indices))}\n",
    "        \n",
    "        # Now make subset and general ID maps and pickle them\n",
    "        self.target_ids.sort()\n",
    "        target_id_map = {self.target_ids[i]:i for i in range(len(self.target_ids))}\n",
    "        target_id_map.update(general_id_map)\n",
    "        \n",
    "        print(\"Target ID Map: \\n {}\".format(target_id_map))\n",
    "        print(\"General ID Map: \\n {}\".format(general_id_map))\n",
    "\n",
    "        # Now pickle these\n",
    "        f_out = os.path.join(os.getcwd(), \"data\", \"ID_MAPS.pkl\")\n",
    "        with open(f_out, \"wb\") as f:\n",
    "            pickle.dump([general_id_indices, general_id_map], f)\n",
    "            f.close()\n",
    "            \n",
    "        for index in range(self.N): # Iterate over all images\n",
    "            FOUND = False\n",
    "            if index % 10000 == 0:\n",
    "                print(\"Iterated through {} files\".format(index))\n",
    "            unique_ids = np.unique(self.labels[index])\n",
    "            for ID in unique_ids:\n",
    "                if ID in self.target_ids:\n",
    "                    labels = self.labels[index]\n",
    "                    mapped_labels = [target_id_map[labels[j]] for j in range(len(labels))]\n",
    "                    target_ds[self.ids[index]] = {'points':self.xyz[index], 'labels':mapped_labels, 'rgb':self.rgb[index]}\n",
    "                    FOUND = True\n",
    "            if not FOUND:\n",
    "                gen_ds[self.ids[index]] = {'points':self.xyz[index], 'labels':self.labels[index], 'rgb':self.rgb[index]}\n",
    "        print(\"Number of pcs in general: {}, Number of pcs in target: {}\".format(len(list(gen_ds.keys())),\\\n",
    "                                                                                 len(list(target_ds.keys()))))\n",
    "        return gen_ds, target_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_wrapper(f_dataset, normalize_xyz=True, normalize_rgb=True,\\\n",
    "                              take_subset=False, convert_to_tensor=True):\n",
    "    # Get input dataset\n",
    "    with open(f_dataset, \"rb\") as f:\n",
    "        dataset = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    # Instantiate the class object\n",
    "    dataloader = A2D2DataLoader(dataset, normalize_xyz=normalize_xyz, normalize_rgb=normalize_rgb, \\\n",
    "                                take_subset=take_subset, convert_to_tensor=convert_to_tensor)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Full Dataset with All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYZ normalized\n",
      "RGB normalized\n",
      "SMALLEST PC POINTS: 55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2f8a87c44905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get input dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset_pc_labels_camera_start_0_stop_10000.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataloader_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtake_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished processing dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-dcbc2a2b0dea>\u001b[0m in \u001b[0;36mcreate_dataloader_wrapper\u001b[0;34m(f_dataset, normalize_xyz, normalize_rgb, take_subset, convert_to_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Instantiate the class object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     dataloader = A2D2DataLoader(dataset, normalize_xyz=normalize_xyz, normalize_rgb=normalize_rgb, \\\n\u001b[0;32m---> 10\u001b[0;31m                                 take_subset=take_subset, convert_to_tensor=convert_to_tensor)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1cdfba57bb12>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, rotation, normalize_xyz, normalize_rgb, take_subset, convert_to_tensor, target_ids)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_norm_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_norm_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_rgb_norm_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1cdfba57bb12>\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mlabels_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mxyz_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mrgb_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mxyz_rgb_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_rgb_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-1cdfba57bb12>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mlabels_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mxyz_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mrgb_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mxyz_rgb_norm_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_rgb_norm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create datasets and save them\n",
    "\n",
    "# Get input dataset\n",
    "f_in = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_10000.pkl\")\n",
    "dataset = create_dataloader_wrapper(f_in, take_subset=False)\n",
    "print(\"Finished processing dataset\")\n",
    "\n",
    "# Create output fname\n",
    "f_out = os.path.join(os.getcwd(),\"data\",\"PROCESSED_mini_dataset_norm_tensor.pkl\")\n",
    "\n",
    "'''\n",
    "# Pickle results\n",
    "with open(f_out, \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "    f.close()\n",
    "'''\n",
    "    \n",
    "print(\"Pickled processed dataset to {}\".format(f_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset with General and Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYZ normalized\n",
      "RGB normalized\n",
      "SMALLEST PC POINTS: 55\n",
      "Target ID Map: \n",
      " {3: 0, 0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53}\n",
      "General ID Map: \n",
      " {0: 0, 1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53}\n",
      "Iterated through 0 files\n",
      "Number of pcs in general: 7519, Number of pcs in target: 2474\n",
      "Finished processing dataset\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and save them\n",
    "\n",
    "# Get input dataset\n",
    "f_in = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_10000_COMBINED_CLASSES.pkl\")\n",
    "dataset = create_dataloader_wrapper(f_in, take_subset=True)\n",
    "print(\"Finished processing dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get general and target datasets\n",
    "gen_ds, target_ds = dataset.general_dataset, dataset.target_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process General Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYZ normalized\n",
      "RGB normalized\n",
      "SMALLEST PC POINTS: 55\n",
      "UNIQUE LABELS: [0 1 2 5]\n",
      "Pickled general processed dataset to /home/ubuntu/869_final_project/point-cloud-transfer-learning/data/PROCESSED_general_dataset_start_0_stop_10000_COMBINED CLASSES.pkl\n"
     ]
    }
   ],
   "source": [
    "# Now create A2D2Dataloader Objects based off of these datasets\n",
    "gen_dataset = A2D2DataLoader(gen_ds, normalize_xyz=True, normalize_rgb=True, \\\n",
    "                                take_subset=False, convert_to_tensor=True)\n",
    "\n",
    "print(\"UNIQUE LABELS: {}\".format(np.unique(gen_dataset.labels[0])))\n",
    "      \n",
    "# Create output fname\n",
    "f_out_general = os.path.join(os.getcwd(),\"data\",\"PROCESSED_general_dataset_start_0_stop_10000_COMBINED CLASSES.pkl\")\n",
    "\n",
    "\n",
    "# Pickle results - general\n",
    "with open(f_out_general, \"wb\") as f:\n",
    "    pickle.dump(gen_ds, f)\n",
    "    f.close()\n",
    "\n",
    "print(\"Pickled general processed dataset to {}\".format(f_out_general))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Target Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XYZ normalized\n",
      "RGB normalized\n",
      "SMALLEST PC POINTS: 611\n",
      "UNIQUE LABELS: [0 1 2 3 4]\n",
      "Pickled target processed dataset to /home/ubuntu/869_final_project/point-cloud-transfer-learning/data/PROCESSED_target_dataset_start_0_stop_10000_COMBINED_CLASSES.pkl\n"
     ]
    }
   ],
   "source": [
    "target_dataset = A2D2DataLoader(target_ds, normalize_xyz=True, normalize_rgb=True, \\\n",
    "                                take_subset=False, convert_to_tensor=True)\n",
    "\n",
    "print(\"UNIQUE LABELS: {}\".format(np.unique(target_dataset.labels[0])))\n",
    "\n",
    "# Create output fname\n",
    "f_out_target = os.path.join(os.getcwd(),\"data\",\"PROCESSED_target_dataset_start_0_stop_10000_COMBINED_CLASSES.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# Pickle results - general\n",
    "with open(f_out_target, \"wb\") as f:\n",
    "    pickle.dump(gen_ds, f)\n",
    "    f.close()\n",
    "\n",
    "print(\"Pickled target processed dataset to {}\".format(f_out_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram of Points over Point Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get distribution of number of training points\n",
    "lengths = []\n",
    "for i in range(dataset.N):\n",
    "    lengths.append(min(len(dataset.xyz[i]), 20000))\n",
    "\n",
    "# Now plot\n",
    "plt.hist(lengths,50)\n",
    "plt.title(\"Histogram of Number of Points in Point Cloud for A2D2 Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check for Dataset Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-97b42fc53529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtest_load_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"PROCESSED_mini_dataset_norm_tensor.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-97b42fc53529>\u001b[0m in \u001b[0;36mtest_load_datasets\u001b[0;34m(f_pickle)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_load_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_pickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyz_norm_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pctl/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_load_datasets(f_pickle):\n",
    "    with open(f_pickle, \"rb\") as f:\n",
    "        D = pickle.load(f)\n",
    "        f.close()\n",
    "    print(D.xyz_norm_tensor[0].numpy().shape)\n",
    "    print(D.rgb_norm_tensor[0].numpy().shape)\n",
    "    print(D.xyz_rgb_norm_tensor[0].numpy().shape)\n",
    "    print(D.labels_tensor[0].numpy().shape)\n",
    "    \n",
    "    print(\"MAX XYZ\", np.max(D.xyz_norm_tensor[0].numpy()))\n",
    "    print(\"MIN XYZ\", np.min(D.xyz_norm_tensor[0].numpy()))\n",
    "    print(\"MAX RGB\", np.max(D.rgb_norm_tensor[0].numpy()))\n",
    "    print(\"MIN RGB\", np.min(D.rgb_norm_tensor[0].numpy()))\n",
    "    print(\"MAX LABEL\", np.max(D.labels_tensor[0].numpy()))\n",
    "    print(\"MIN LABEL\", np.min(D.labels_tensor[0].numpy()))\n",
    "\n",
    "    print(\"GET MIN NUMBER OF POINTS\")\n",
    "    \n",
    "\n",
    "test_load_datasets(os.path.join(os.getcwd(),\"data\",\"PROCESSED_mini_dataset_norm_tensor.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use to find which labels are present in which classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seen_matrix(dataloader):\n",
    "    # Now we want to determine which classes appear the fewest number of times\n",
    "    seen = {i: 0 for i in range(55)}\n",
    "    print(seen)\n",
    "    count = 0\n",
    "    for index in range(dataloader.N): # Iterate over each image\n",
    "        if count % 1000 == 0:\n",
    "            print(\"Iterated through {} point clouds\".format(count))\n",
    "        seen_i = {j: 0 for j in range(55)}\n",
    "        for label in dataloader.labels[index]:\n",
    "            seen_i[label] = 1\n",
    "        copy_seen = copy.deepcopy(seen)\n",
    "        seen = {k:seen_i[k]+copy_seen[k] for k in range(55)}\n",
    "        count += 1\n",
    "    return seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the rarest classes for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_n_rarest_classes(dataloader,n=10): \n",
    "    seen = create_seen_matrix(dataloader)\n",
    "    sorted_seen = sorted(seen.items(), key=operator.itemgetter(1))\n",
    "    return sorted_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0, 50: 0, 51: 0, 52: 0, 53: 0, 54: 0}\n",
      "Iterated through 0 point clouds\n",
      "Iterated through 1000 point clouds\n",
      "Iterated through 2000 point clouds\n",
      "Iterated through 3000 point clouds\n",
      "Iterated through 4000 point clouds\n",
      "Iterated through 5000 point clouds\n",
      "Iterated through 6000 point clouds\n",
      "Iterated through 7000 point clouds\n",
      "Iterated through 8000 point clouds\n",
      "Iterated through 9000 point clouds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(19, 0),\n",
       " (26, 0),\n",
       " (46, 0),\n",
       " (7, 1),\n",
       " (54, 1),\n",
       " (18, 3),\n",
       " (31, 18),\n",
       " (24, 20),\n",
       " (53, 23),\n",
       " (16, 24),\n",
       " (33, 35),\n",
       " (37, 40),\n",
       " (15, 55),\n",
       " (13, 71),\n",
       " (3, 100),\n",
       " (41, 104),\n",
       " (10, 139),\n",
       " (22, 181),\n",
       " (6, 217),\n",
       " (42, 297),\n",
       " (23, 408),\n",
       " (14, 415),\n",
       " (5, 448),\n",
       " (9, 533),\n",
       " (12, 647),\n",
       " (21, 675),\n",
       " (48, 761),\n",
       " (44, 1260),\n",
       " (36, 1327),\n",
       " (17, 1382),\n",
       " (4, 1648),\n",
       " (47, 1728),\n",
       " (8, 1907),\n",
       " (2, 2167),\n",
       " (32, 2606),\n",
       " (39, 2975),\n",
       " (34, 3316),\n",
       " (38, 3358),\n",
       " (25, 3422),\n",
       " (1, 3509),\n",
       " (40, 3880),\n",
       " (30, 4132),\n",
       " (29, 4881),\n",
       " (11, 4971),\n",
       " (45, 4994),\n",
       " (20, 5142),\n",
       " (52, 5274),\n",
       " (27, 5534),\n",
       " (35, 6590),\n",
       " (0, 7124),\n",
       " (28, 7976),\n",
       " (51, 7999),\n",
       " (49, 8286),\n",
       " (43, 9861),\n",
       " (50, 9892)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_rarest_classes(dataset, n=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Label Counts Across the Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 files\n",
      "Processed 1000 files\n",
      "Processed 2000 files\n",
      "Processed 3000 files\n",
      "Processed 4000 files\n",
      "Processed 5000 files\n",
      "Processed 6000 files\n",
      "Processed 7000 files\n",
      "Processed 8000 files\n",
      "Processed 9000 files\n",
      "{0: 35790091, 1: 23047847}\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance affects performance - let's fix that!\n",
    "full_dataset_file = os.path.join(os.getcwd(), \"data\", \"dataset_pc_labels_camera_start_0_stop_28652.pkl\")\n",
    "\n",
    "# Also compare for combined classes dataset\n",
    "combined_classes_dataset = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_0_stop_10000_COMBINED_CLASSES.pkl\")\n",
    "\n",
    "# Also compare for road detection dataset\n",
    "road_detection_dataset = os.path.join(os.getcwd(), \"data\", \\\n",
    "                            \"dataset_pc_labels_camera_start_0_stop_10000_ROAD_DETECTION.pkl\")\n",
    "\n",
    "# Import pickle file\n",
    "with open(road_detection_dataset, \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "full_label_counts = {i:0 for i in range(55)}\n",
    "combined_label_counts = {i:0 for i in range(6)}\n",
    "road_detection_label_counts = {i:0 for i in range(2)}\n",
    "    \n",
    "keys = list(D.keys())\n",
    "count = 0\n",
    "\n",
    "for key in keys:\n",
    "    if count % 1000 == 0:\n",
    "        print(\"Processed {} files\".format(count))\n",
    "    for label in D[key]['labels']:\n",
    "        road_detection_label_counts[label] += 1\n",
    "    count += 1\n",
    "\n",
    "print(road_detection_label_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle Class Weights File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 35790091, 1: 23047847}\n"
     ]
    }
   ],
   "source": [
    "# Pickle this dictionary to file\n",
    "class_weights_fpath = os.path.join(os.getcwd(), \"data\", \"class_weights_ROAD_DETECTION.pkl\")\n",
    "\n",
    "print(road_detection_label_counts)\n",
    "\n",
    "with open(class_weights_fpath, \"wb\") as f:\n",
    "    pickle.dump(road_detection_label_counts, f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test New Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classes for general dataset\n",
    "with open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptl",
   "language": "python",
   "name": "ptl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
